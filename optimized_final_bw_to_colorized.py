# -*- coding: utf-8 -*-
"""Optimized_Final_BW_To_Colorized.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TlIjl-78EOHG3X-xZ8JRGqX_EDRFAYCz

# 442 Final Project
Authors: Mandy Chen, Aidan McKiernan, Harry Jung, Tony Lee

For our final project, our group has chosen to perform automatic image colorization by reimplementing the paper "Colorful Image Colorization" by Zhang et al. We will be developing a computer vision model that can take a grayscale image and produce a realistically colorized output.

The changes we have made include modifying the model and changing certain parameters to better accomadate a smaller data set. We also are using TensorFlow instead and came up with our own method of training. Loading and pre/postprocessing are implemented with direct influence from the paper by Zhang et. al.
"""

!pip install tensorflow -q

import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from sklearn.cluster import KMeans
from sklearn.cluster import MiniBatchKMeans
from skimage import color
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
tf.experimental.numpy.experimental_enable_numpy_behavior()
print(f"TensorFlow version: {tf.__version__}")

import kagglehub

path = kagglehub.dataset_download("nitishabharathi/scene-classification")

print("Path to dataset files:", path)

image_paths = os.listdir(path + '/train-scene classification/train')
print(image_paths)
image_paths = [path + '/train-scene classification/train/' + f for f in image_paths]

def load_img(img_path):
    out_np = np.asarray(Image.open(img_path).convert('RGB'))
    if out_np.ndim == 2:
        out_np = np.tile(out_np[:, :, None], 3)
    return out_np

def resize_img(img, HW=(150, 150), resample=Image.BICUBIC):
    if img.ndim == 4 and img.shape[0] == 1:
        img = img[0]
    if img.dtype != np.uint8:
        img = (img * 255).astype(np.uint8)
    return np.asarray(Image.fromarray(img).resize((HW[1], HW[0]), resample=resample))

def preprocess_img(img_rgb_orig, HW=(150, 150), resample=Image.BICUBIC):
    img_rgb_rs = resize_img(img_rgb_orig, HW=HW, resample=resample)
    img_lab_orig = color.rgb2lab(img_rgb_orig)
    img_lab_rs = color.rgb2lab(img_rgb_rs)

    img_l_orig = img_lab_orig[:, :, 0]
    img_l_rs = img_lab_rs[:, :, 0]
    img_ab_orig = img_lab_orig[:, :, 1:]
    img_ab_rs = img_lab_rs[:, :, 1:]

    tens_orig_l = tf.convert_to_tensor(img_l_orig, dtype=tf.float32)[tf.newaxis, :, :, tf.newaxis]
    tens_rs_l = tf.convert_to_tensor(img_l_rs, dtype=tf.float32)[tf.newaxis, :, :, tf.newaxis]
    tens_ab_orig = tf.convert_to_tensor(img_ab_orig, dtype=tf.float32)[tf.newaxis, :, :, :]
    tens_ab_rs = tf.convert_to_tensor(img_ab_rs, dtype=tf.float32)[tf.newaxis, :, :, :]

    return (tens_orig_l, tens_rs_l, tens_ab_orig, tens_ab_rs)

def postprocess_tens(tens_orig_l, out_ab, mode='bilinear', quantized_ab_path="quantized_ab_values.npy"):
    quantized_ab = np.load(quantized_ab_path)

    out_ab_idx = tf.argmax(out_ab, axis=-1)
    out_ab_vals = tf.gather(quantized_ab, out_ab_idx)

    HW_orig = tf.shape(tens_orig_l)[1:3]
    out_ab_orig = tf.image.resize(out_ab_vals, size=HW_orig)

    tens_orig_l = tf.squeeze(tens_orig_l, axis=-1)
    tens_orig_l = tens_orig_l[..., tf.newaxis]

    out_lab_orig = tf.concat([tens_orig_l, out_ab_orig], axis=-1)

    out_lab_orig_np = out_lab_orig.numpy()[0, ...]
    return color.lab2rgb(out_lab_orig_np)

def compute_quantized_ab(dataset_paths, num_bins=313):
    ab_values = []
    for img_path in dataset_paths:
        img_rgb = np.asarray(Image.open(img_path).convert('RGB'))
        img_lab = color.rgb2lab(img_rgb)
        ab_values.append(img_lab[:, :, 1:].reshape(-1, 2))
    ab_values = np.vstack(ab_values)
    #kmeans = KMeans(n_clusters=num_bins, random_state=42).fit(ab_values)
    kmeans = MiniBatchKMeans(n_clusters=num_bins, random_state=42).fit(ab_values)
    return kmeans.cluster_centers_

def quantize_ab(img_ab, q_ab_bins):
    ab_shape = img_ab.shape[:2]
    img_ab_flat = img_ab.reshape(-1, 2)
    distances = np.linalg.norm(img_ab_flat[:, None] - q_ab_bins[None, :], axis=2)
    quantized_idxs = np.argmin(distances, axis=1)
    return quantized_idxs.reshape(ab_shape)

def preprocess_training_data(img_paths, HW=(256, 256), q_ab_bins=None):
    X, Y = [], []
    for img_path in img_paths:
        img_rgb = np.asarray(Image.open(img_path).convert('RGB'))
        img_rgb_rs = resize_img(img_rgb, HW=HW)
        img_lab = color.rgb2lab(img_rgb_rs)
        img_l = img_lab[:, :, 0]
        img_ab = img_lab[:, :, 1:]
        img_ab_bins = quantize_ab(img_ab, q_ab_bins)
        img_ab_bins = to_categorical(img_ab_bins, num_classes=len(q_ab_bins))
        X.append(img_l)
        Y.append(img_ab_bins)
    return np.array(X)[..., np.newaxis], np.array(Y)

def build_colorization_model(input_shape=(150, 150, 1)):
    inputs = layers.Input(shape=input_shape)
    x = layers.Conv2D(64, 3, padding='same')(inputs)
    x = layers.ReLU()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(128, 3, padding='same')(x)
    x = layers.ReLU()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(128, 3, padding='same')(x)
    x = layers.ReLU()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(256, 3, padding='same')(x)
    x = layers.ReLU()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(256, 3, padding='same')(x)
    x = layers.ReLU()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(512, 3, padding='same')(x)
    x = layers.ReLU()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(32, 3, padding='same', dilation_rate=2)(x)
    x = layers.ReLU()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(40, 1, padding='same')(x)
    outputs = layers.Softmax()(x)

    return Model(inputs=inputs, outputs=outputs)

def color_distribution_loss(y_true, y_pred):
    return tf.keras.losses.categorical_crossentropy(y_true, y_pred)

# Training
dataset_paths = image_paths[:2000] # Number of images used for training
q_ab = compute_quantized_ab(dataset_paths, num_bins=40)
np.save("quantized_ab_values.npy", q_ab)

X_train, Y_train = preprocess_training_data(dataset_paths, HW=(100, 100), q_ab_bins=q_ab)

model = build_colorization_model(input_shape=(100, 100, 1))

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss=color_distribution_loss,
    metrics=['accuracy']
)

model.fit(X_train, Y_train, batch_size=50, epochs=25, validation_split=0.1)
model.save_weights("colorization.weights.h5")

# Inference
model.load_weights("colorization.weights.h5")
test_img_paths = image_paths[-20:-10] # Number of images used for validation
colorized_img_paths = []
for test_img in test_img_paths:
    test_img = load_img(test_img)
    tens_orig_l, tens_rs_l, _, _ = preprocess_img(test_img, HW=(100, 100))
    out_ab = model.predict(tens_rs_l)
    colorized_img = postprocess_tens(tens_orig_l, out_ab)
    colorized_img_paths.append(colorized_img)

# Evaluation
for colorized_img in colorized_img_paths:
    plt.imshow(colorized_img)
    plt.axis('off')
    plt.show()